{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NW Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/UNSW_NB15_training-set.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82332, 45)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>45332</td>\n",
       "      <td>55.060001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>37000</td>\n",
       "      <td>44.939999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Count  Percentage\n",
       "0      1  45332   55.060001\n",
       "1      0  37000   44.939999"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_df['label']\n",
    "train_y_df = train_y.reset_index()\n",
    "cnt_y = train_y_df.label.value_counts().reset_index()\n",
    "cnt_y.columns = ['Class', 'Count']\n",
    "total_y = cnt_y.Count.sum()\n",
    "cnt_y[\"Percentage\"] =(cnt_y.Count/total_y)*100\n",
    "cnt_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x127b647f0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAGYCAYAAABrrmq0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127b3a6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha_bar_chart = 0.55\n",
    "train_df['attack_cat'].value_counts().plot(kind='bar', alpha=alpha_bar_chart)\n",
    "# puts a title on our graph\n",
    "plt.title(\"Distribution of category\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>90909.0902</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.0003</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1068</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0051</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>166666.6608</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2126</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0   1  0.000011   udp       -   INT      2      0     496       0   \n",
       "1   2  0.000008   udp       -   INT      2      0    1762       0   \n",
       "2   3  0.000005   udp       -   INT      2      0    1068       0   \n",
       "3   4  0.000006   udp       -   INT      2      0     900       0   \n",
       "4   5  0.000010   udp       -   INT      2      0    2126       0   \n",
       "\n",
       "          rate  ...    ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "0   90909.0902  ...                   1               2             0   \n",
       "1  125000.0003  ...                   1               2             0   \n",
       "2  200000.0051  ...                   1               3             0   \n",
       "3  166666.6608  ...                   1               3             0   \n",
       "4  100000.0025  ...                   1               3             0   \n",
       "\n",
       "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
       "0           0                 0           1           2                0   \n",
       "1           0                 0           1           2                0   \n",
       "2           0                 0           1           3                0   \n",
       "3           0                 0           2           3                0   \n",
       "4           0                 0           2           3                0   \n",
       "\n",
       "   attack_cat  label  \n",
       "0      Normal      0  \n",
       "1      Normal      0  \n",
       "2      Normal      0  \n",
       "3      Normal      0  \n",
       "4      Normal      0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.drop(['label','attack_cat','id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for attribute in [\"proto\",\"service\",\"state\"]:\n",
    "    le_attribute = preprocessing.LabelEncoder()   \n",
    "    train[attribute] = le_attribute.fit_transform(train[attribute])\n",
    "X = train.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_data = pd.get_dummies(train).values  # one-hot encoding. change category value to numberica value matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X_data[:train.shape[0]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train a classfiier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (65865, 42) (16467, 42)\n",
      "0.529116660648\n",
      "0.527667413931\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.88      0.76      7400\n",
      "          1       0.87      0.65      0.74      9067\n",
      "\n",
      "avg / total       0.78      0.75      0.75     16467\n",
      "\n",
      "Fold 2 (65865, 42) (16467, 42)\n",
      "0.528194933479\n",
      "0.51759742656\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.87      0.76      7400\n",
      "          1       0.86      0.67      0.75      9067\n",
      "\n",
      "avg / total       0.78      0.76      0.76     16467\n",
      "\n",
      "Fold 3 (65866, 42) (16466, 42)\n",
      "0.527851299815\n",
      "0.529765003826\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.87      0.76      7400\n",
      "          1       0.86      0.66      0.75      9066\n",
      "\n",
      "avg / total       0.78      0.75      0.75     16466\n",
      "\n",
      "Fold 4 (65866, 42) (16466, 42)\n",
      "0.52655129189\n",
      "0.534116248486\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.86      0.76      7400\n",
      "          1       0.86      0.66      0.75      9066\n",
      "\n",
      "avg / total       0.78      0.75      0.75     16466\n",
      "\n",
      "Fold 5 (65866, 42) (16466, 42)\n",
      "0.548064891704\n",
      "0.550556935651\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.87      0.76      7400\n",
      "          1       0.86      0.66      0.75      9066\n",
      "\n",
      "avg / total       0.78      0.75      0.75     16466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics, model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "n_folds = 5\n",
    "kf = model_selection.StratifiedKFold(n_splits=n_folds, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "#target_names = {'class 1','class 2','class 3','class 4','class 5','class 6','class 7','class 8','class 9'}\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    fold += 1\n",
    "    X_train, X_valid    = X[train_index], X[test_index]\n",
    "    y_train, y_valid    = y[train_index], y[test_index]\n",
    "    \n",
    "    print(\"Fold\", fold, X_train.shape, X_valid.shape)\n",
    "    \n",
    "    clf = LogisticRegression(C=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    p_train = clf.predict_proba(X_train)\n",
    "    p_valid = clf.predict_proba(X_valid)\n",
    "        \n",
    "    y_predict_train = clf.predict(X_train)\n",
    "    y_predict_valid = clf.predict(X_valid)\n",
    "    \n",
    "\n",
    "    print(metrics.log_loss(y_train, p_train))\n",
    "    print(metrics.log_loss(y_valid, p_valid))\n",
    "    print(classification_report(y_valid, y_predict_valid))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (65865, 42) (16467, 42)\n",
      "SVM correct prediction: 0.67\n",
      "Fold 2 (65865, 42) (16467, 42)\n",
      "SVM correct prediction: 0.63\n",
      "Fold 3 (65866, 42) (16466, 42)\n",
      "SVM correct prediction: 0.45\n",
      "Fold 4 (65866, 42) (16466, 42)\n",
      "SVM correct prediction: 0.71\n",
      "Fold 5 (65866, 42) (16466, 42)\n",
      "SVM correct prediction: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "n_folds = 5\n",
    "kf = model_selection.StratifiedKFold(n_splits=n_folds, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "#target_names = {'class 1','class 2','class 3','class 4','class 5','class 6','class 7','class 8','class 9'}\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    fold += 1\n",
    "    X_train, X_valid    = X[train_index], X[test_index]\n",
    "    y_train, y_valid    = y[train_index], y[test_index]\n",
    "    \n",
    "    print(\"Fold\", fold, X_train.shape, X_valid.shape)\n",
    "    \n",
    "    clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=   5, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "        \n",
    "    y_predict_train = clf.predict(X_train)\n",
    "    y_predict_valid = clf.predict(X_valid)\n",
    "    \n",
    "\n",
    "    #print(metrics.log_loss(y_train, p_train))\n",
    "    #print(metrics.log_loss(y_valid, p_valid))\n",
    "    print('SVM correct prediction: {:4.2f}'.format(np.mean(y_predict_valid == y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (65865, 42) (16467, 42)\n",
      "SVM correct prediction: 0.75\n",
      "Fold 2 (65865, 42) (16467, 42)\n",
      "SVM correct prediction: 0.76\n",
      "Fold 3 (65866, 42) (16466, 42)\n",
      "SVM correct prediction: 0.75\n",
      "Fold 4 (65866, 42) (16466, 42)\n",
      "SVM correct prediction: 0.75\n",
      "Fold 5 (65866, 42) (16466, 42)\n",
      "SVM correct prediction: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "X = preprocessing.normalize(X, norm='l2')\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "n_folds = 5\n",
    "kf = model_selection.StratifiedKFold(n_splits=n_folds, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "#target_names = {'class 1','class 2','class 3','class 4','class 5','class 6','class 7','class 8','class 9'}\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    fold += 1\n",
    "    X_train, X_valid    = X[train_index], X[test_index]\n",
    "    y_train, y_valid    = y[train_index], y[test_index]\n",
    "    \n",
    "    print(\"Fold\", fold, X_train.shape, X_valid.shape)\n",
    "    \n",
    "    clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=   5, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "        \n",
    "    y_predict_train = clf.predict(X_train)\n",
    "    y_predict_valid = clf.predict(X_valid)\n",
    "    \n",
    "\n",
    "    #print(metrics.log_loss(y_train, p_train))\n",
    "    #print(metrics.log_loss(y_valid, p_valid))\n",
    "    print('SVM correct prediction: {:4.2f}'.format(np.mean(y_predict_valid == y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (65865, 42) (16467, 42)\n",
      "0.750045545637\n",
      "Fold 2 (65865, 42) (16467, 42)\n",
      "0.757697212607\n",
      "Fold 3 (65866, 42) (16466, 42)\n",
      "0.752581076157\n",
      "Fold 4 (65866, 42) (16466, 42)\n",
      "0.752520344953\n",
      "Fold 5 (65866, 42) (16466, 42)\n",
      "0.752945463379\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "n_folds = 5\n",
    "kf = model_selection.StratifiedKFold(n_splits=n_folds, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "#target_names = {'class 1','class 2','class 3','class 4','class 5','class 6','class 7','class 8','class 9'}\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    fold += 1\n",
    "    X_train, X_valid    = X[train_index], X[test_index]\n",
    "    y_train, y_valid    = y[train_index], y[test_index]\n",
    "    \n",
    "    print(\"Fold\", fold, X_train.shape, X_valid.shape)\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    p_train = clf.predict_proba(X_train)\n",
    "    p_valid = clf.predict_proba(X_valid)\n",
    "        \n",
    "    y_predict_train = clf.predict(X_train)\n",
    "    y_predict_valid = clf.predict(X_valid)\n",
    "    \n",
    "\n",
    "    #print(metrics.log_loss(y_train, p_train))\n",
    "    #print(metrics.log_loss(y_valid, p_valid))\n",
    "    print(np.mean(y_predict_valid == y_valid))   \n",
    "    #print(classification_report(y_valid, y_predict_valid))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (65865, 42) (16467, 42)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-c6ce72ef50de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mp_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mp_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaojuan/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \"\"\"\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaojuan/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[1;32m    583\u001b[0m                                  \" probability=False\")\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'c_svc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nu_svc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "n_folds = 5\n",
    "kf = model_selection.StratifiedKFold(n_splits=n_folds, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "#target_names = {'class 1','class 2','class 3','class 4','class 5','class 6','class 7','class 8','class 9'}\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    fold += 1\n",
    "    X_train, X_valid    = X[train_index], X[test_index]\n",
    "    y_train, y_valid    = y[train_index], y[test_index]\n",
    "    \n",
    "    print(\"Fold\", fold, X_train.shape, X_valid.shape)\n",
    "    \n",
    "    clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "    p_train = clf.predict_proba(X_train)\n",
    "    p_valid = clf.predict_proba(X_valid)\n",
    "        \n",
    "    y_predict_train = clf.predict(X_train)\n",
    "    y_predict_valid = clf.predict(X_valid)\n",
    "    \n",
    "\n",
    "    #print(metrics.log_loss(y_train, p_train))\n",
    "    #print(metrics.log_loss(y_valid, p_valid))\n",
    "    print(np.mean(y_predict_valid == y_valid))   \n",
    "    #print(classification_report(y_valid, y_predict_valid))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
